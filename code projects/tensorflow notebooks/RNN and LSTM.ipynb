{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS152Fa19Assign6 Mohamed E",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXZhKwMXGknU"
      },
      "source": [
        "# Assignment 6: Calculate parity using an RNN\n",
        "\n",
        "In this assignment, you'll be using an LSTM recurrent neural network with one hidden state to learn the parity of a sequence of binary values of length 50.\n",
        "\n",
        "The LSTM layer in Keras works slightly differently from the LSTM described in class. In particular, it does not have $\\hat{y}$ outputs. Instead, by default, the LSTM layer outputs $h_T$, the hidden state of the last timestep.  Alternatively (using the `return_sequences` parameter to the constructor), it'll return the vector of *all* hidden states: $[h_1, h_2, ..., h_T]$. If you want to duplicate the output of the LSTM we discussed in class, you'd need to feed the output of the LSTM layer to a `Dense` layer that runs it through a weight matrix and activation function.\n",
        "\n",
        "### Steps\n",
        "1. First, attempt to solve the problem using only the last hidden state, $h_T$ of the LSTM (that is, the loss function will only consider whether the parity of the entire sequence is correct or incorrect).  With a long sequence, this can be difficult.  Can you get this to work with sequences shorter than 50?\n",
        "2. Next, try using *all* of the hidden states of the LSTM, and have your loss function consider not just whether your NN has learned to predict the parity of the entire sequence, but also whether your NN has learned to predict the parity of each of the sequence prefixes (that is, whether $\\hat{y_i}$ is the parity of the values $x_1, ..., x_i$ for each $i$). This approach should be able to solve the problem fairly easily.\n",
        "\n",
        "Make sure your notebook shows *both* attempts to solve the problem.\n",
        "\n",
        "\n",
        "### Hints\n",
        "  * You'll likely find that `mse` is probably a better loss function than any form of cross-entropy.\n",
        "  * Expect that the accuracy of the NN hovers around 50% for several epochs until it abruptly improves to close to 100%.\n",
        "  * Useful routines:\n",
        "    * `np.random.randint`\n",
        "    * `np.sum`\n",
        "    * `np.cumsum`\n",
        "  * I suggest you create a dataset of large size (random `x` along with associated `y`).  The `fit` function has a `validation_split` paramater which'll split off some validation data automatically.\n",
        "\n",
        "### Misc\n",
        "You may use Keras/Tensorflow reference information,  other blogs or tutorials, Stack Overflow, etc., as long as the material referenced doesn't specifically address solving the parity problem.\n",
        "\n",
        "\n",
        "This assignment is due on Thursday, December 12, at 11 PM.  Name the notebook `CS152Fa19Assign6YOURNAME`. Please share the notebook with rhodes@g.hmc.edu. Make sure you have done a fresh run of all the cells before you turn it in, and that you make no changes to the notebook after the due date.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksLLNzIYfeUI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b3c98b5-67a4-4984-d1ed-daf9ca62db21"
      },
      "source": [
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4do-Kt3XUhZb"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONF_7XcG-Kws"
      },
      "source": [
        "# Part 1 (using strings of len 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKh8Fy57UZMR"
      },
      "source": [
        "## Create Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzpwlmeoUeIy"
      },
      "source": [
        "inputs = np.random.randint(2, size=(15000, 15, 1)) * 1.0\n",
        "labels = inputs.cumsum(axis=1) % 2 * 1.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swWQDDQ-btSL"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMgtvvjbbxIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "49daab47-337c-4ffa-c7ef-b4eeaee41c7d"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(1))\n",
        "model.compile(optimizer='RMSprop', loss='mse', metrics=['accuracy','mse'])\n",
        "model.fit(x=inputs, y=labels,epochs=10, batch_size=15, verbose=1, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11250 samples, validate on 3750 samples\n",
            "Epoch 1/10\n",
            "11250/11250 [==============================] - 5s 477us/sample - loss: 0.3018 - accuracy: 0.5013 - mse: 0.3018 - val_loss: 0.2502 - val_accuracy: 0.4996 - val_mse: 0.2502\n",
            "Epoch 2/10\n",
            "11250/11250 [==============================] - 3s 310us/sample - loss: 0.2500 - accuracy: 0.5026 - mse: 0.2500 - val_loss: 0.2500 - val_accuracy: 0.5037 - val_mse: 0.2500\n",
            "Epoch 3/10\n",
            "11250/11250 [==============================] - 4s 320us/sample - loss: 0.2499 - accuracy: 0.5052 - mse: 0.2499 - val_loss: 0.2500 - val_accuracy: 0.4983 - val_mse: 0.2500\n",
            "Epoch 4/10\n",
            "11250/11250 [==============================] - 4s 320us/sample - loss: 0.2499 - accuracy: 0.5048 - mse: 0.2499 - val_loss: 0.2500 - val_accuracy: 0.4991 - val_mse: 0.2500\n",
            "Epoch 5/10\n",
            "11250/11250 [==============================] - 4s 323us/sample - loss: 0.2499 - accuracy: 0.5040 - mse: 0.2499 - val_loss: 0.2499 - val_accuracy: 0.4990 - val_mse: 0.2499\n",
            "Epoch 6/10\n",
            "11250/11250 [==============================] - 4s 316us/sample - loss: 0.2499 - accuracy: 0.5064 - mse: 0.2499 - val_loss: 0.2499 - val_accuracy: 0.5143 - val_mse: 0.2499\n",
            "Epoch 7/10\n",
            "11250/11250 [==============================] - 4s 316us/sample - loss: 0.2499 - accuracy: 0.5063 - mse: 0.2499 - val_loss: 0.2499 - val_accuracy: 0.5034 - val_mse: 0.2499\n",
            "Epoch 8/10\n",
            "11250/11250 [==============================] - 4s 313us/sample - loss: 0.2499 - accuracy: 0.5054 - mse: 0.2499 - val_loss: 0.2500 - val_accuracy: 0.4996 - val_mse: 0.2500\n",
            "Epoch 9/10\n",
            "11250/11250 [==============================] - 4s 316us/sample - loss: 0.2499 - accuracy: 0.5057 - mse: 0.2499 - val_loss: 0.2498 - val_accuracy: 0.5070 - val_mse: 0.2498\n",
            "Epoch 10/10\n",
            "11250/11250 [==============================] - 4s 320us/sample - loss: 0.2498 - accuracy: 0.5071 - mse: 0.2498 - val_loss: 0.2498 - val_accuracy: 0.5148 - val_mse: 0.2498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2acb4f2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tho561rI-T43"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7CIqdFR-gk6"
      },
      "source": [
        "### Create database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqlA7gbH-WOK"
      },
      "source": [
        "inputs = np.random.randint(2, size=(15000, 50, 1)) * 1.0\n",
        "labels = inputs.cumsum(axis=1) % 2 * 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVHO6PNT-jPY"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5y0-tIK-mnc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "6526d2ab-15b1-4075-cf4a-87a22327dbae"
      },
      "source": [
        "model_2 = tf.keras.models.Sequential()\n",
        "model_2.add(tf.keras.layers.LSTM(1,return_sequences=True))\n",
        "model_2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "model_2.compile(optimizer='RMSprop', loss='mse', metrics=['accuracy','mse'])\n",
        "model_2.fit(x=inputs, y=labels,epochs=10, batch_size=5, verbose=1, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11250 samples, validate on 3750 samples\n",
            "Epoch 1/10\n",
            "11250/11250 [==============================] - 14s 1ms/sample - loss: 0.2504 - accuracy: 0.4998 - mse: 0.2504 - val_loss: 0.2500 - val_accuracy: 0.4991 - val_mse: 0.2500\n",
            "Epoch 2/10\n",
            "11250/11250 [==============================] - 12s 1ms/sample - loss: 0.2500 - accuracy: 0.5024 - mse: 0.2500 - val_loss: 0.2500 - val_accuracy: 0.5089 - val_mse: 0.2500\n",
            "Epoch 3/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.2500 - accuracy: 0.5065 - mse: 0.2500 - val_loss: 0.2499 - val_accuracy: 0.5120 - val_mse: 0.2499\n",
            "Epoch 4/10\n",
            "11250/11250 [==============================] - 12s 1ms/sample - loss: 0.2499 - accuracy: 0.5114 - mse: 0.2499 - val_loss: 0.2499 - val_accuracy: 0.5122 - val_mse: 0.2499\n",
            "Epoch 5/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.2498 - accuracy: 0.5130 - mse: 0.2498 - val_loss: 0.2498 - val_accuracy: 0.5140 - val_mse: 0.2498\n",
            "Epoch 6/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.2496 - accuracy: 0.5147 - mse: 0.2496 - val_loss: 0.2494 - val_accuracy: 0.5142 - val_mse: 0.2494\n",
            "Epoch 7/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.2485 - accuracy: 0.5188 - mse: 0.2485 - val_loss: 0.2465 - val_accuracy: 0.5293 - val_mse: 0.2465\n",
            "Epoch 8/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.2307 - accuracy: 0.6220 - mse: 0.2307 - val_loss: 0.1466 - val_accuracy: 0.9654 - val_mse: 0.1466\n",
            "Epoch 9/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.0461 - accuracy: 0.9988 - mse: 0.0461 - val_loss: 0.0125 - val_accuracy: 1.0000 - val_mse: 0.0125\n",
            "Epoch 10/10\n",
            "11250/11250 [==============================] - 13s 1ms/sample - loss: 0.0055 - accuracy: 1.0000 - mse: 0.0055 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_mse: 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2a3b99c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    }
  ]
}